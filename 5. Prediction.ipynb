{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vietnamese_char_dict = {\n",
    "    ('a', 5): 'á',\n",
    "    ('a', 9): 'à',\n",
    "    ('a', 13): 'ả',\n",
    "    ('a', 17): 'ã',\n",
    "    ('a', 21): 'ạ',\n",
    "    ('a', 1): 'â',\n",
    "    ('a', 6): 'ấ',\n",
    "    ('a', 10): 'ầ',\n",
    "    ('a', 14): 'ẩ',\n",
    "    ('a', 18): 'ẫ',\n",
    "    ('a', 22): 'ậ',\n",
    "    ('a', 3): 'ă',\n",
    "    ('a', 8): 'ắ',\n",
    "    ('a', 12): 'ằ',\n",
    "    ('a', 16): 'ẳ',\n",
    "    ('a', 20): 'ẵ',\n",
    "    ('a', 24): 'ặ',\n",
    "    ('d', 4): 'đ',\n",
    "    ('e', 5): 'é',\n",
    "    ('e', 9): 'è',\n",
    "    ('e', 13): 'ẻ',\n",
    "    ('e', 17): 'ẽ',\n",
    "    ('e', 21): 'ẹ',\n",
    "    ('e', 1): 'ê',\n",
    "    ('e', 6): 'ế',\n",
    "    ('e', 10): 'ề',\n",
    "    ('e', 14): 'ể',\n",
    "    ('e', 18): 'ễ',\n",
    "    ('e', 22): 'ệ',\n",
    "    ('i', 5): 'í',\n",
    "    ('i', 9): 'ì',\n",
    "    ('i', 13): 'ỉ',\n",
    "    ('i', 17): 'ĩ',\n",
    "    ('i', 21): 'ị',\n",
    "    ('o', 5): 'ó',\n",
    "    ('o', 9): 'ò',\n",
    "    ('o', 13): 'ỏ',\n",
    "    ('o', 17): 'õ',\n",
    "    ('o', 21): 'ọ',\n",
    "    ('o', 1): 'ô',\n",
    "    ('o', 6): 'ố',\n",
    "    ('o', 10): 'ồ',\n",
    "    ('o', 14): 'ổ',\n",
    "    ('o', 18): 'ỗ',\n",
    "    ('o', 22): 'ộ',\n",
    "    ('o', 2): 'ơ',\n",
    "    ('o', 7): 'ớ',\n",
    "    ('o', 11): 'ờ',\n",
    "    ('o', 15): 'ở',\n",
    "    ('o', 19): 'ỡ',\n",
    "    ('o', 23): 'ợ',\n",
    "    ('u', 5): 'ú',\n",
    "    ('u', 9): 'ù',\n",
    "    ('u', 13): 'ủ',\n",
    "    ('u', 17): 'ũ',\n",
    "    ('u', 21): 'ụ',\n",
    "    ('u', 2): 'ư',\n",
    "    ('u', 7): 'ứ',\n",
    "    ('u', 11): 'ừ',\n",
    "    ('u', 15): 'ử',\n",
    "    ('u', 19): 'ữ',\n",
    "    ('u', 23): 'ự',\n",
    "    ('y', 5): 'ý',\n",
    "    ('y', 9): 'ỳ',\n",
    "    ('y', 13): 'ỷ',\n",
    "    ('y', 17): 'ỹ',\n",
    "    ('y', 21): 'ỵ'\n",
    "}\n",
    "\n",
    "alphabet_dict = {\n",
    "    'a': 0,\n",
    "    'b': 1,\n",
    "    'c': 2,\n",
    "    'd': 3,\n",
    "    'e': 4,\n",
    "    'f': 5,\n",
    "    'g': 6,\n",
    "    'h': 7,\n",
    "    'i': 8,\n",
    "    'j': 9,\n",
    "    'k': 10,\n",
    "    'l': 11,\n",
    "    'm': 12,\n",
    "    'n': 13,\n",
    "    'o': 14,\n",
    "    'p': 15,\n",
    "    'q': 16,\n",
    "    'r': 17,\n",
    "    's': 18,\n",
    "    't': 19,\n",
    "    'u': 20,\n",
    "    'v': 21,\n",
    "    'w': 22,\n",
    "    'x': 23,\n",
    "    'y': 24,\n",
    "    'z': 25,\n",
    "    ' ': 26\n",
    "}\n",
    "\n",
    "reverse_alphabet_dict = {v: k for k, v in alphabet_dict.items()}\n",
    "\n",
    "alphabet_size = len(alphabet_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def represent(line_int_repr, tone_int_repr):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        line_int_repr: a list of int represents the tone-removed characters (english alphabet or blank space)\n",
    "        tone_int_repr: a list of int represents the tone marks\n",
    "    Returns:\n",
    "        str, a vietnamese unicode string\n",
    "    \"\"\"\n",
    "    line_char_repr = [reverse_alphabet_dict[key] for key in line_int_repr]\n",
    "    vietnamese_char_list = [vietnamese_char_dict[(char, tone)] if (char, tone) in vietnamese_char_dict.keys() else char \n",
    "                            for char, tone in zip(line_char_repr, tone_int_repr)]\n",
    "    return ''.join(vietnamese_char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tone_mark(lowercase_sentence, model):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        lowercase_sentence: a string consists of only characters from alphabet_dict (english alphabet + blank space)\n",
    "        model: trained keras model, input shape (None, None, alphabet_size), output shape (None, None, tone_size)\n",
    "    Returns:\n",
    "        str, a vietnamese unicode string with predicted tone marks\n",
    "    \"\"\"\n",
    "    X_int = [alphabet_dict[char] for char in lowercase_sentence]\n",
    "    X = np.array([to_categorical(X_int, num_classes=alphabet_size)])\n",
    "    y = model.predict(X).squeeze()\n",
    "    tone_int = np.argmax(y, -1)\n",
    "    return represent(X_int, tone_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are taken directly from https://github.com/aivivn/vietnamese_tone_prediction_utils/blob/master/utils.py\n",
    "\n",
    "def remove_tone_line(utf8_str):\n",
    "    intab_l = \"ạảãàáâậầấẩẫăắằặẳẵóòọõỏôộổỗồốơờớợởỡéèẻẹẽêếềệểễúùụủũưựữửừứíìịỉĩýỳỷỵỹđ\"\n",
    "    intab_u = \"ẠẢÃÀÁÂẬẦẤẨẪĂẮẰẶẲẴÓÒỌÕỎÔỘỔỖỒỐƠỜỚỢỞỠÉÈẺẸẼÊẾỀỆỂỄÚÙỤỦŨƯỰỮỬỪỨÍÌỊỈĨÝỲỶỴỸĐ\"\n",
    "    intab = intab_l + intab_u\n",
    "\n",
    "    outtab_l = \"a\"*17 + \"o\"*17 + \"e\"*11 + \"u\"*11 + \"i\"*5 + \"y\"*5 + \"d\"\n",
    "    outtab_u = \"A\"*17 + \"O\"*17 + \"E\"*11 + \"U\"*11 + \"I\"*5 + \"Y\"*5 + \"D\"\n",
    "    outtab = outtab_l + outtab_u\n",
    "\n",
    "    r = re.compile(\"|\".join(intab))\n",
    "    replaces_dict = dict(zip(intab, outtab))\n",
    "\n",
    "    return r.sub(lambda m: replaces_dict[m.group(0)], utf8_str)\n",
    "\n",
    "\n",
    "def normalize_tone_line(utf8_str):\n",
    "    intab_l = \"áàảãạâấầẩẫậăắằẳẵặđèéẻẽẹêếềểễệíìỉĩịóòỏõọôốồổỗộơớờởỡợúùủũụưứừửữựýỳỷỹỵ\"\n",
    "    intab_u = \"ÁÀẢÃẠÂẤẦẨẪẬĂẮẰẲẴẶĐÈÉẺẼẸÊẾỀỂỄỆÍÌỈĨỊÓÒỎÕỌÔỐỒỔỖỘƠỚỜỞỠỢÚÙỦŨỤƯỨỪỬỮỰÝỲỶỸỴ\"\n",
    "    intab = intab_l + intab_u\n",
    "\n",
    "    outtab_l = [\n",
    "        \"a1\", \"a2\", \"a3\", \"a4\", \"a5\",\n",
    "        \"a6\", \"a61\", \"a62\", \"a63\", \"a64\", \"a65\",\n",
    "        \"a8\", \"a81\", \"a82\", \"a83\", \"a84\", \"a85\",\n",
    "        \"d9\",\n",
    "        \"e1\", \"e2\", \"e3\", \"e4\", \"e5\",\n",
    "        \"e6\", \"e61\", \"e62\", \"e63\", \"e64\", \"e65\",\n",
    "        \"i1\", \"i2\", \"i3\", \"i4\", \"i5\",\n",
    "        \"o1\", \"o2\", \"o3\", \"o4\", \"o5\",\n",
    "        \"o6\", \"a61\", \"o62\", \"o63\", \"o64\", \"o65\",\n",
    "        \"o7\", \"o71\", \"o72\", \"o73\", \"o74\", \"o75\",\n",
    "        \"u1\", \"u2\", \"u3\", \"u4\", \"u5\",\n",
    "        \"u7\", \"u71\", \"u72\", \"u73\", \"u74\", \"u75\",\n",
    "        \"y1\", \"y2\", \"y3\", \"y4\", \"y5\",\n",
    "    ]\n",
    "\n",
    "    outtab_u = [\n",
    "        \"A1\", \"A2\", \"A3\", \"A4\", \"A5\",\n",
    "        \"A6\", \"A61\", \"A62\", \"A63\", \"A64\", \"A65\",\n",
    "        \"A8\", \"A81\", \"A82\", \"A83\", \"A84\", \"A85\",\n",
    "        \"D9\",\n",
    "        \"E1\", \"E2\", \"E3\", \"E4\", \"E5\",\n",
    "        \"E6\", \"E61\", \"E62\", \"E63\", \"E64\", \"E65\",\n",
    "        \"I1\", \"I2\", \"I3\", \"I4\", \"I5\",\n",
    "        \"O1\", \"O2\", \"O3\", \"O4\", \"O5\",\n",
    "        \"O6\", \"O61\", \"O62\", \"O63\", \"O64\", \"O65\",\n",
    "        \"O7\", \"O71\", \"O72\", \"O73\", \"O74\", \"O75\",\n",
    "        \"U1\", \"U2\", \"U3\", \"U4\", \"U5\",\n",
    "        \"U7\", \"U71\", \"U72\", \"U73\", \"U74\", \"U75\",\n",
    "        \"Y1\", \"Y2\", \"Y3\", \"Y4\", \"Y5\",\n",
    "    ]\n",
    "\n",
    "    r = re.compile(\"|\".join(intab))\n",
    "    replaces_dict = dict(zip(intab, outtab_l + outtab_u))\n",
    "\n",
    "    return r.sub(lambda m: replaces_dict[m.group(0)], utf8_str)\n",
    "\n",
    "\n",
    "def simplify(word):\n",
    "    \"\"\"\n",
    "    normalize and simplify a vni word:\n",
    "    * move tone digit to the end\n",
    "    * return only digits\n",
    "    * return 0 if there is no digit\n",
    "    \"\"\"\n",
    "    if word.isalpha(): \n",
    "        return '0'\n",
    "    ret = ''\n",
    "    tone = ''\n",
    "    for letter in word:\n",
    "        if '1' <= letter <= '9':\n",
    "            if '1' <= letter <= '5':\n",
    "                # assert len(tone) == 0, '{}, {}'.format(tone, word)\n",
    "                if tone != '':\n",
    "                    return '#'  # ignore this word\n",
    "                tone = letter\n",
    "            else:\n",
    "                ret += letter\n",
    "    return ret + tone\n",
    "\n",
    "\n",
    "def my_simplify(word):\n",
    "    \"\"\"\n",
    "    normalize and simplify a vni word:\n",
    "    * move tone digit to the end\n",
    "    * return only digits\n",
    "    * return 0 if there is no digit\n",
    "    \"\"\"\n",
    "    if word.isalpha(): \n",
    "        return '0'\n",
    "    ret = ''\n",
    "    tone = ''\n",
    "    for letter in word:\n",
    "        if '1' <= letter <= '9':\n",
    "            if '1' <= letter <= '5':\n",
    "                tone = letter\n",
    "            else:\n",
    "                ret += letter\n",
    "    return ret + tone\n",
    "\n",
    "\n",
    "def process_line(line):\n",
    "    \"\"\"\n",
    "    Process a line\n",
    "    :param line:\n",
    "    :return: no_tone_line, no_tone_words, simplified_words\n",
    "    \"\"\"\n",
    "    utf8_line = line.strip('\\n')\n",
    "\n",
    "    no_tone_line_pre = remove_tone_line(utf8_line)\n",
    "    normalized_line_pre = normalize_tone_line(utf8_line)\n",
    "\n",
    "    no_tone_line_alphanumeric = re.sub('[^a-zA-Z\\d]', ' ', repr(no_tone_line_pre))\n",
    "    normalized_line_alphanumeric = re.sub('[^a-zA-Z\\d]', ' ', repr(normalized_line_pre))\n",
    "\n",
    "    no_tone_words = no_tone_line_alphanumeric.split()\n",
    "    normalized_words = normalized_line_alphanumeric.split()\n",
    "    assert len(no_tone_words) == len(normalized_words)\n",
    "\n",
    "    filtered_no_tone_words = []\n",
    "    simplified_words = []\n",
    "    for i, word in enumerate(no_tone_words):\n",
    "        if not word.isalpha():\n",
    "            continue\n",
    "#         simplified_word = simplify(normalized_words[i])\n",
    "        simplified_word = my_simplify(normalized_words[i])\n",
    "#         if simplified_word == '#':\n",
    "#             continue\n",
    "        filtered_no_tone_words.append(word)\n",
    "        simplified_words.append(simplified_word)\n",
    "\n",
    "    return filtered_no_tone_words, simplified_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(lowercase_sentence, model):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        lowercase_sentence: a string consists of only characters from alphabet_dict (english alphabet + blank space)\n",
    "        model: trained keras model, input shape (None, None, alphabet_size), output shape (None, None, tone_size)\n",
    "    Returns:\n",
    "        str, a list of labels, one label for each word (for submission)\n",
    "    \"\"\"\n",
    "    vietnamese_string = predict_tone_mark(lowercase_sentence, model)\n",
    "    _, labels = process_line(vietnamese_string)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tai xe dung xe phan doi tram thu bot can tho phung hiep trong may ngay qua dong thoi cac don vi chuc nang cu luc luong tuc truc dam bao an ninh trat tu tai khu vuc tranh de doi tuong xau loi dung xuyen tac chu truong cua dang chinh sach phap luat cua nha nuoc'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.loc[1012]['sentence'].lower()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tài xế dừng xe phản đối trạm thu bot cần thơ phụng hiệp trong mấy ngày qua đồng thời các đơn vị chức năng cử lực lượng túc trục đảm bảo an ninh trật tự tại khu vực tranh để đối tượng xấu lợi dụng xuyên tạc chủ trương của đảng chính sách pháp luật của nhà nước'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_tone_mark(x, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n"
     ]
    }
   ],
   "source": [
    "row_list = []\n",
    "for idx, row in df.iterrows():\n",
    "    sentence_id = row['id']\n",
    "    sentence = row['sentence']\n",
    "    label_list = get_label(sentence.lower(), model)\n",
    "    for i, label in enumerate(label_list):\n",
    "        word_id = '{}{:03}'.format(sentence_id, i)\n",
    "        row_list.append({'id': word_id, 'label': label})\n",
    "    if idx % 100 == 0:\n",
    "        print(idx)\n",
    "submission = pd.DataFrame(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
