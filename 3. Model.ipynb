{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import LSTM, Bidirectional, Dense, Activation, TimeDistributed, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_dict = {\n",
    "    'a': 0,\n",
    "    'b': 1,\n",
    "    'c': 2,\n",
    "    'd': 3,\n",
    "    'e': 4,\n",
    "    'f': 5,\n",
    "    'g': 6,\n",
    "    'h': 7,\n",
    "    'i': 8,\n",
    "    'j': 9,\n",
    "    'k': 10,\n",
    "    'l': 11,\n",
    "    'm': 12,\n",
    "    'n': 13,\n",
    "    'o': 14,\n",
    "    'p': 15,\n",
    "    'q': 16,\n",
    "    'r': 17,\n",
    "    's': 18,\n",
    "    't': 19,\n",
    "    'u': 20,\n",
    "    'v': 21,\n",
    "    'w': 22,\n",
    "    'x': 23,\n",
    "    'y': 24,\n",
    "    'z': 25,\n",
    "    ' ': 26\n",
    "}\n",
    "\n",
    "alphabet_size = len(alphabet_dict)\n",
    "\n",
    "tone_dict = {\n",
    "    (0, 0): 0,\n",
    "    (0, 6): 1,\n",
    "    (0, 7): 2,\n",
    "    (0, 8): 3,\n",
    "    (0, 9): 4,\n",
    "    (1, 0): 5,\n",
    "    (1, 6): 6,\n",
    "    (1, 7): 7,\n",
    "    (1, 8): 8,\n",
    "    (2, 0): 9,\n",
    "    (2, 6): 10,\n",
    "    (2, 7): 11,\n",
    "    (2, 8): 12,\n",
    "    (3, 0): 13,\n",
    "    (3, 6): 14,\n",
    "    (3, 7): 15,\n",
    "    (3, 8): 16,\n",
    "    (4, 0): 17,\n",
    "    (4, 6): 18,\n",
    "    (4, 7): 19,\n",
    "    (4, 8): 20,\n",
    "    (5, 0): 21,\n",
    "    (5, 6): 22,\n",
    "    (5, 7): 23,\n",
    "    (5, 8): 24\n",
    "}\n",
    "\n",
    "tone_size = len(tone_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'training'\n",
    "validation_dir = 'validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(data_dir, batch_size=32):\n",
    "    while True:\n",
    "        for f_path in glob.glob(os.path.join(data_dir, \"*.txt\")):\n",
    "            with open(f_path, 'r', encoding='utf-8') as f:\n",
    "                X_train = []\n",
    "                y_train = []\n",
    "                for line in f:\n",
    "                    line = line.strip('\\n')\n",
    "                    char, tone = line.split(',')\n",
    "                    char = list(map(int, char.split()))\n",
    "                    tone = list(map(int, tone.split()))\n",
    "                    X_train.append(to_categorical(char, num_classes=alphabet_size)) # one-hot encoding\n",
    "                    y_train.append(to_categorical(tone, num_classes=tone_size)) # one-hot encoding\n",
    "                X_train = np.array(X_train)\n",
    "                y_train = np.array(y_train)\n",
    "                \n",
    "#                 n_samples = X_train.shape[0]\n",
    "#                 if (n_samples % batch_size) != 0:\n",
    "#                     repeats = batch_size - n_samples % batch_size\n",
    "#                     X_last = np.repeat([X_train[-1]], repeats=repeats, axis=0)\n",
    "#                     X_train = np.vstack([X_train, X_last])\n",
    "#                     y_last = np.repeat([y_train[-1]], repeats=repeats, axis=0)\n",
    "#                     y_train = np.vstack([y_train, y_last])\n",
    "                    \n",
    "                for i in range(X_train.shape[0] // batch_size):\n",
    "                    yield X_train[i*batch_size:(i+1)*batch_size], y_train[i*batch_size:(i+1)*batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(100, return_sequences=True), \n",
    "                        input_shape=(None, alphabet_size)))\n",
    "model.add(Dense(tone_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=1e-4)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(batch_generator(data_dir=train_dir), steps_per_epoch=70000, epochs=1,\n",
    "                    validation_data=batch_generator(data_dir=validation_dir), validation_steps=3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
